{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a66f704e",
   "metadata": {
    "id": "a66f704e"
   },
   "source": [
    "# FRE7773 - Machine Learning in Financial Engineering\n",
    "# Assignment 4\n",
    "# Please submit this .ipynb file on Brightspace before **11:59 pm 11 December**."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "451681df",
   "metadata": {
    "id": "451681df"
   },
   "source": [
    "## Models:\n",
    "1. Deep learning for regression problem (30 points)\n",
    "2. Recurrent Neural Networks (RNN) (30 points)\n",
    "3. Deep Learning for Classification - Back-propagation from Scratch (40 points)\n",
    "\n",
    "### General Guidelines:\n",
    "1. You can choose the same or different financial applications for each model.\n",
    "2. All your work, from explanations to code and analysis, should be presented within a\n",
    "single Jupyter notebook.\n",
    "3. While reusing content from other sources is allowed, always ensure you provide\n",
    "appropriate citations and references.\n",
    "4. This is an individual assignment. Adhere strictly to NYU’s policy on plagiarism. Late\n",
    "submissions will not be accepted and will result in a deduction of 10 points (if late more\n",
    "than 24h, will result in a deduction of 20 points).\n",
    "### Key Emphasis:\n",
    "While accuracy is valuable, a descriptive, clear, and convincing implementation and analysis of\n",
    "your models hold greater weight in this assignment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8358761e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8358761e",
    "outputId": "c9eec669-c6ef-46e2-b90c-8076f0fa8376"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fastparquet in /Applications/anaconda3/lib/python3.12/site-packages (2024.11.0)\n",
      "Requirement already satisfied: pandas>=1.5.0 in /Applications/anaconda3/lib/python3.12/site-packages (from fastparquet) (2.2.2)\n",
      "Requirement already satisfied: numpy in /Applications/anaconda3/lib/python3.12/site-packages (from fastparquet) (1.26.4)\n",
      "Requirement already satisfied: cramjam>=2.3 in /Applications/anaconda3/lib/python3.12/site-packages (from fastparquet) (2.9.0)\n",
      "Requirement already satisfied: fsspec in /Applications/anaconda3/lib/python3.12/site-packages (from fastparquet) (2024.3.1)\n",
      "Requirement already satisfied: packaging in /Applications/anaconda3/lib/python3.12/site-packages (from fastparquet) (23.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Applications/anaconda3/lib/python3.12/site-packages (from pandas>=1.5.0->fastparquet) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in /Applications/anaconda3/lib/python3.12/site-packages (from pandas>=1.5.0->fastparquet) (2024.1)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Applications/anaconda3/lib/python3.12/site-packages (from pandas>=1.5.0->fastparquet) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /Applications/anaconda3/lib/python3.12/site-packages (from python-dateutil>=2.8.2->pandas>=1.5.0->fastparquet) (1.16.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: tensorflow in /Applications/anaconda3/lib/python3.12/site-packages (2.18.0)\n",
      "Requirement already satisfied: absl-py>=1.0.0 in /Applications/anaconda3/lib/python3.12/site-packages (from tensorflow) (2.1.0)\n",
      "Requirement already satisfied: astunparse>=1.6.0 in /Applications/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.6.3)\n",
      "Requirement already satisfied: flatbuffers>=24.3.25 in /Applications/anaconda3/lib/python3.12/site-packages (from tensorflow) (24.3.25)\n",
      "Requirement already satisfied: gast!=0.5.0,!=0.5.1,!=0.5.2,>=0.2.1 in /Applications/anaconda3/lib/python3.12/site-packages (from tensorflow) (0.6.0)\n",
      "Requirement already satisfied: google-pasta>=0.1.1 in /Applications/anaconda3/lib/python3.12/site-packages (from tensorflow) (0.2.0)\n",
      "Requirement already satisfied: libclang>=13.0.0 in /Applications/anaconda3/lib/python3.12/site-packages (from tensorflow) (18.1.1)\n",
      "Requirement already satisfied: opt-einsum>=2.3.2 in /Applications/anaconda3/lib/python3.12/site-packages (from tensorflow) (3.4.0)\n",
      "Requirement already satisfied: packaging in /Applications/anaconda3/lib/python3.12/site-packages (from tensorflow) (23.2)\n",
      "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<6.0.0dev,>=3.20.3 in /Applications/anaconda3/lib/python3.12/site-packages (from tensorflow) (3.20.3)\n",
      "Requirement already satisfied: requests<3,>=2.21.0 in /Applications/anaconda3/lib/python3.12/site-packages (from tensorflow) (2.32.2)\n",
      "Requirement already satisfied: setuptools in /Applications/anaconda3/lib/python3.12/site-packages (from tensorflow) (69.5.1)\n",
      "Requirement already satisfied: six>=1.12.0 in /Applications/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.16.0)\n",
      "Requirement already satisfied: termcolor>=1.1.0 in /Applications/anaconda3/lib/python3.12/site-packages (from tensorflow) (2.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.6 in /Applications/anaconda3/lib/python3.12/site-packages (from tensorflow) (4.11.0)\n",
      "Requirement already satisfied: wrapt>=1.11.0 in /Applications/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.14.1)\n",
      "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /Applications/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.68.1)\n",
      "Requirement already satisfied: tensorboard<2.19,>=2.18 in /Applications/anaconda3/lib/python3.12/site-packages (from tensorflow) (2.18.0)\n",
      "Requirement already satisfied: keras>=3.5.0 in /Applications/anaconda3/lib/python3.12/site-packages (from tensorflow) (3.7.0)\n",
      "Requirement already satisfied: numpy<2.1.0,>=1.26.0 in /Applications/anaconda3/lib/python3.12/site-packages (from tensorflow) (1.26.4)\n",
      "Requirement already satisfied: h5py>=3.11.0 in /Applications/anaconda3/lib/python3.12/site-packages (from tensorflow) (3.11.0)\n",
      "Requirement already satisfied: ml-dtypes<0.5.0,>=0.4.0 in /Applications/anaconda3/lib/python3.12/site-packages (from tensorflow) (0.4.1)\n",
      "Requirement already satisfied: wheel<1.0,>=0.23.0 in /Applications/anaconda3/lib/python3.12/site-packages (from astunparse>=1.6.0->tensorflow) (0.43.0)\n",
      "Requirement already satisfied: rich in /Applications/anaconda3/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (13.3.5)\n",
      "Requirement already satisfied: namex in /Applications/anaconda3/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (0.0.8)\n",
      "Requirement already satisfied: optree in /Applications/anaconda3/lib/python3.12/site-packages (from keras>=3.5.0->tensorflow) (0.13.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Applications/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Applications/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Applications/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Applications/anaconda3/lib/python3.12/site-packages (from requests<3,>=2.21.0->tensorflow) (2024.8.30)\n",
      "Requirement already satisfied: markdown>=2.6.8 in /Applications/anaconda3/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.4.1)\n",
      "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /Applications/anaconda3/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (0.7.2)\n",
      "Requirement already satisfied: werkzeug>=1.0.1 in /Applications/anaconda3/lib/python3.12/site-packages (from tensorboard<2.19,>=2.18->tensorflow) (3.0.3)\n",
      "Requirement already satisfied: MarkupSafe>=2.1.1 in /Applications/anaconda3/lib/python3.12/site-packages (from werkzeug>=1.0.1->tensorboard<2.19,>=2.18->tensorflow) (2.1.3)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /Applications/anaconda3/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Applications/anaconda3/lib/python3.12/site-packages (from rich->keras>=3.5.0->tensorflow) (2.15.1)\n",
      "Requirement already satisfied: mdurl~=0.1 in /Applications/anaconda3/lib/python3.12/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich->keras>=3.5.0->tensorflow) (0.1.0)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n",
      "Requirement already satisfied: yfinance in /Applications/anaconda3/lib/python3.12/site-packages (0.2.44)\n",
      "Requirement already satisfied: pandas>=1.3.0 in /Applications/anaconda3/lib/python3.12/site-packages (from yfinance) (2.2.2)\n",
      "Requirement already satisfied: numpy>=1.16.5 in /Applications/anaconda3/lib/python3.12/site-packages (from yfinance) (1.26.4)\n",
      "Requirement already satisfied: requests>=2.31 in /Applications/anaconda3/lib/python3.12/site-packages (from yfinance) (2.32.2)\n",
      "Requirement already satisfied: multitasking>=0.0.7 in /Applications/anaconda3/lib/python3.12/site-packages (from yfinance) (0.0.11)\n",
      "Requirement already satisfied: lxml>=4.9.1 in /Applications/anaconda3/lib/python3.12/site-packages (from yfinance) (5.2.1)\n",
      "Requirement already satisfied: platformdirs>=2.0.0 in /Applications/anaconda3/lib/python3.12/site-packages (from yfinance) (3.10.0)\n",
      "Requirement already satisfied: pytz>=2022.5 in /Applications/anaconda3/lib/python3.12/site-packages (from yfinance) (2024.1)\n",
      "Requirement already satisfied: frozendict>=2.3.4 in /Applications/anaconda3/lib/python3.12/site-packages (from yfinance) (2.4.2)\n",
      "Requirement already satisfied: peewee>=3.16.2 in /Applications/anaconda3/lib/python3.12/site-packages (from yfinance) (3.17.6)\n",
      "Requirement already satisfied: beautifulsoup4>=4.11.1 in /Applications/anaconda3/lib/python3.12/site-packages (from yfinance) (4.12.3)\n",
      "Requirement already satisfied: html5lib>=1.1 in /Applications/anaconda3/lib/python3.12/site-packages (from yfinance) (1.1)\n",
      "Requirement already satisfied: soupsieve>1.2 in /Applications/anaconda3/lib/python3.12/site-packages (from beautifulsoup4>=4.11.1->yfinance) (2.5)\n",
      "Requirement already satisfied: six>=1.9 in /Applications/anaconda3/lib/python3.12/site-packages (from html5lib>=1.1->yfinance) (1.16.0)\n",
      "Requirement already satisfied: webencodings in /Applications/anaconda3/lib/python3.12/site-packages (from html5lib>=1.1->yfinance) (0.5.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /Applications/anaconda3/lib/python3.12/site-packages (from pandas>=1.3.0->yfinance) (2.9.0.post0)\n",
      "Requirement already satisfied: tzdata>=2022.7 in /Applications/anaconda3/lib/python3.12/site-packages (from pandas>=1.3.0->yfinance) (2023.3)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Applications/anaconda3/lib/python3.12/site-packages (from requests>=2.31->yfinance) (2.0.4)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /Applications/anaconda3/lib/python3.12/site-packages (from requests>=2.31->yfinance) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Applications/anaconda3/lib/python3.12/site-packages (from requests>=2.31->yfinance) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Applications/anaconda3/lib/python3.12/site-packages (from requests>=2.31->yfinance) (2024.8.30)\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.3.1\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "# install the package\n",
    "! pip install fastparquet\n",
    "! pip install tensorflow\n",
    "! pip install yfinance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dadf1f68",
   "metadata": {
    "id": "dadf1f68"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "import datetime\n",
    "import tensorflow as tf\n",
    "import yfinance as yf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.datasets import mnist\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.layers import Dense, LSTM\n",
    "from tensorflow.keras.layers import SimpleRNN, Dense\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad5daa61",
   "metadata": {
    "id": "ad5daa61"
   },
   "source": [
    "# 1. Deep learning for regression problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "348d7e55",
   "metadata": {
    "id": "348d7e55"
   },
   "source": [
    "## 1.1 Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1f76d74",
   "metadata": {
    "id": "a1f76d74"
   },
   "source": [
    "**Problem Statement:**\n",
    "\n",
    "- The problem at hand involves predicting the future price of Apple Inc. (AAPL) stock based on historical price data and relevant market indicators.\n",
    "\n",
    "- For this problem, we will utilize a Multilayer Perceptron (MLP) regression model. MLP models are versatile neural networks capable of learning nonlinear relationships between input features and target variables. By training an MLP regression model on historical price data and relevant market indicators for AAPL stock, we aim to build a predictive model that can accurately forecast the numerical value of future stock prices.\n",
    "\n",
    "- The solution to this problem enables traders and investors to make more informed decisions about buying, selling, or holding AAPL stock. By accurately predicting the numerical value of future stock prices, traders can implement more effective trading strategies, such as buying AAPL stock when prices are expected to increase or selling when prices are expected to decrease. Ultimately, this can lead to improved portfolio performance and potentially higher profits in the stock market.\n",
    "\n",
    "**Data Description:**\n",
    "\n",
    "The dataset used in this project contains historical price data of AAPL stock\n",
    "\n",
    "1. **Timeframe**: 2014.1.1-2024.1.1\n",
    "2. **Geography**: The dataset primarily focuses on AAPL stock trading in the United States market.\n",
    "3. **Source**: yahoo finance\n",
    "4. **Target variable:**closing price of AAPL stock price.\n",
    "5. **Features:** The independent (features) variables consist of various market indicators and historical price data, including opening price, closing price, highest price, lowest price, trading volume."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ab5933",
   "metadata": {
    "id": "86ab5933"
   },
   "source": [
    "## 1.2 Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b91925f5",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 287
    },
    "id": "b91925f5",
    "outputId": "35f136d7-abc5-4874-8ffb-0fa95f63a2d9"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[*********************100%***********************]  1 of 1 completed\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Open</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Close</th>\n",
       "      <th>Adj Close</th>\n",
       "      <th>Volume</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2014-01-02</th>\n",
       "      <td>19.845715</td>\n",
       "      <td>19.893929</td>\n",
       "      <td>19.715000</td>\n",
       "      <td>19.754642</td>\n",
       "      <td>17.234293</td>\n",
       "      <td>234684800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-03</th>\n",
       "      <td>19.745001</td>\n",
       "      <td>19.775000</td>\n",
       "      <td>19.301071</td>\n",
       "      <td>19.320715</td>\n",
       "      <td>16.855732</td>\n",
       "      <td>392467600</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-06</th>\n",
       "      <td>19.194643</td>\n",
       "      <td>19.528570</td>\n",
       "      <td>19.057142</td>\n",
       "      <td>19.426071</td>\n",
       "      <td>16.947651</td>\n",
       "      <td>412610800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-07</th>\n",
       "      <td>19.440001</td>\n",
       "      <td>19.498571</td>\n",
       "      <td>19.211430</td>\n",
       "      <td>19.287144</td>\n",
       "      <td>16.826437</td>\n",
       "      <td>317209200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-01-08</th>\n",
       "      <td>19.243214</td>\n",
       "      <td>19.484285</td>\n",
       "      <td>19.238930</td>\n",
       "      <td>19.409286</td>\n",
       "      <td>16.933001</td>\n",
       "      <td>258529600</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 Open       High        Low      Close  Adj Close     Volume\n",
       "Date                                                                        \n",
       "2014-01-02  19.845715  19.893929  19.715000  19.754642  17.234293  234684800\n",
       "2014-01-03  19.745001  19.775000  19.301071  19.320715  16.855732  392467600\n",
       "2014-01-06  19.194643  19.528570  19.057142  19.426071  16.947651  412610800\n",
       "2014-01-07  19.440001  19.498571  19.211430  19.287144  16.826437  317209200\n",
       "2014-01-08  19.243214  19.484285  19.238930  19.409286  16.933001  258529600"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fetch historical stock price data from Yahoo Finance\n",
    "ticker = 'AAPL'\n",
    "start_date = '2014-01-01'\n",
    "end_date = '2024-01-01'\n",
    "data = yf.download(ticker, start=start_date, end=end_date)\n",
    "data.index = data.index.strftime('%Y-%m-%d')\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "qTiJnFhkHdPf",
   "metadata": {
    "id": "qTiJnFhkHdPf"
   },
   "source": [
    "#### Train-Test Split\n",
    "Split the dataset into training, validation, and testing sets.\n",
    "The training set comprises 80% of the data, the remaining data is used for testing;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "-4WK0nfgNchZ",
   "metadata": {
    "id": "-4WK0nfgNchZ"
   },
   "outputs": [],
   "source": [
    "\n",
    "X = data.drop('Close', axis=1).iloc[:-1]\n",
    "y = data['Close'].shift(-1).iloc[:-1]\n",
    "X_train_val, X_test, y_train_val, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "lahzNZzimXBH",
   "metadata": {
    "id": "lahzNZzimXBH"
   },
   "outputs": [],
   "source": [
    "# Scale the data\n",
    "scaler = StandardScaler()\n",
    "X_train_val_scaled = scaler.fit_transform(X_train_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Split the validation set;20% of the training set serves as the validation set.\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_val_scaled, y_train_val, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "TJ9QAj4GPqJ4",
   "metadata": {
    "id": "TJ9QAj4GPqJ4"
   },
   "source": [
    "### Implement the MLP model\n",
    "\n",
    "\n",
    "*    Define the architecture of the Multilayer Perceptron (MLP) model, which will be used for regression.\n",
    "*   Configure the model for training by specifying the optimizer and loss function\n",
    "*  The `fit()` method is called on the model, passing the training data and specifying the number of epochs, batch size, and validation data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "DE0LDKlWQxt7",
   "metadata": {
    "id": "DE0LDKlWQxt7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.12/site-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 9183.7959 - mae: 77.6694 - val_loss: 5689.6973 - val_mae: 59.2665\n",
      "Epoch 2/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3598.6208 - mae: 45.1873 - val_loss: 489.9407 - val_mae: 17.2141\n",
      "Epoch 3/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 466.4017 - mae: 16.6911 - val_loss: 340.2370 - val_mae: 14.3181\n",
      "Epoch 4/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 327.1206 - mae: 13.8272 - val_loss: 246.6574 - val_mae: 12.3343\n",
      "Epoch 5/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 273.9019 - mae: 12.7911 - val_loss: 170.2478 - val_mae: 10.4808\n",
      "Epoch 6/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 182.7730 - mae: 10.5756 - val_loss: 106.9088 - val_mae: 8.2475\n",
      "Epoch 7/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 131.4124 - mae: 8.9014 - val_loss: 64.8905 - val_mae: 6.3137\n",
      "Epoch 8/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 89.0133 - mae: 7.3900 - val_loss: 34.5840 - val_mae: 4.6564\n",
      "Epoch 9/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 68.9785 - mae: 6.2840 - val_loss: 19.3957 - val_mae: 3.4708\n",
      "Epoch 10/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 51.8882 - mae: 5.4568 - val_loss: 14.7428 - val_mae: 3.0153\n",
      "Epoch 11/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 41.3669 - mae: 4.9441 - val_loss: 8.0090 - val_mae: 2.2232\n",
      "Epoch 12/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 38.4993 - mae: 4.6593 - val_loss: 6.7336 - val_mae: 1.9793\n",
      "Epoch 13/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 35.8645 - mae: 4.3606 - val_loss: 6.2892 - val_mae: 1.8298\n",
      "Epoch 14/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 34.3808 - mae: 4.2759 - val_loss: 7.9955 - val_mae: 2.0887\n",
      "Epoch 15/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 32.2639 - mae: 4.1813 - val_loss: 4.6566 - val_mae: 1.5616\n",
      "Epoch 16/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 32.8823 - mae: 3.9817 - val_loss: 5.0880 - val_mae: 1.6555\n",
      "Epoch 17/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 27.6632 - mae: 3.7753 - val_loss: 4.6659 - val_mae: 1.4094\n",
      "Epoch 18/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 29.8444 - mae: 3.8927 - val_loss: 4.1335 - val_mae: 1.3391\n",
      "Epoch 19/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 26.6579 - mae: 3.5911 - val_loss: 4.3091 - val_mae: 1.3549\n",
      "Epoch 20/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 24.5535 - mae: 3.5427 - val_loss: 4.2220 - val_mae: 1.2930\n",
      "Epoch 21/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 26.1305 - mae: 3.5877 - val_loss: 4.5564 - val_mae: 1.4239\n",
      "Epoch 22/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 28.6650 - mae: 3.7000 - val_loss: 9.4427 - val_mae: 1.9784\n",
      "Epoch 23/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 33.7046 - mae: 3.7715 - val_loss: 3.8130 - val_mae: 1.2823\n",
      "Epoch 24/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 24.9167 - mae: 3.4152 - val_loss: 4.6213 - val_mae: 1.3813\n",
      "Epoch 25/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 27.3734 - mae: 3.4861 - val_loss: 3.8893 - val_mae: 1.2680\n",
      "Epoch 26/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 25.2578 - mae: 3.3979 - val_loss: 4.5103 - val_mae: 1.3188\n",
      "Epoch 27/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 25.5955 - mae: 3.5396 - val_loss: 4.2855 - val_mae: 1.3260\n",
      "Epoch 28/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 25.0373 - mae: 3.4078 - val_loss: 4.0467 - val_mae: 1.3620\n",
      "Epoch 29/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 24.6731 - mae: 3.3176 - val_loss: 4.1090 - val_mae: 1.3114\n",
      "Epoch 30/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 22.4185 - mae: 3.2366 - val_loss: 3.8094 - val_mae: 1.2270\n",
      "Epoch 31/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 23.1099 - mae: 3.2277 - val_loss: 10.4995 - val_mae: 2.1302\n",
      "Epoch 32/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 25.3667 - mae: 3.3177 - val_loss: 3.7573 - val_mae: 1.2208\n",
      "Epoch 33/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 22.5952 - mae: 3.1093 - val_loss: 4.0263 - val_mae: 1.3152\n",
      "Epoch 34/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 20.3228 - mae: 2.9334 - val_loss: 7.7922 - val_mae: 1.8541\n",
      "Epoch 35/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 25.9162 - mae: 3.3309 - val_loss: 3.8588 - val_mae: 1.3093\n",
      "Epoch 36/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 20.6652 - mae: 3.0388 - val_loss: 4.3828 - val_mae: 1.4054\n",
      "Epoch 37/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 22.4326 - mae: 3.1189 - val_loss: 4.8346 - val_mae: 1.5652\n",
      "Epoch 38/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 24.6835 - mae: 3.2936 - val_loss: 3.9168 - val_mae: 1.3384\n",
      "Epoch 39/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 25.7300 - mae: 3.3217 - val_loss: 4.0200 - val_mae: 1.2585\n",
      "Epoch 40/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 19.5984 - mae: 2.9130 - val_loss: 4.1171 - val_mae: 1.2658\n",
      "Epoch 41/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 20.7818 - mae: 3.0227 - val_loss: 4.8622 - val_mae: 1.4068\n",
      "Epoch 42/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 19.0154 - mae: 2.8799 - val_loss: 3.8718 - val_mae: 1.2357\n",
      "Epoch 43/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 22.0536 - mae: 3.0946 - val_loss: 4.0620 - val_mae: 1.2585\n",
      "Epoch 44/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 20.1297 - mae: 2.9646 - val_loss: 7.1967 - val_mae: 1.7183\n",
      "Epoch 45/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 22.4162 - mae: 2.9891 - val_loss: 4.0681 - val_mae: 1.3307\n",
      "Epoch 46/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 21.3407 - mae: 3.1001 - val_loss: 4.1654 - val_mae: 1.3110\n",
      "Epoch 47/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 24.5236 - mae: 3.1945 - val_loss: 5.6881 - val_mae: 1.5332\n",
      "Epoch 48/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 24.0907 - mae: 3.2270 - val_loss: 3.8091 - val_mae: 1.2795\n",
      "Epoch 49/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 22.9536 - mae: 3.1070 - val_loss: 3.9877 - val_mae: 1.2455\n",
      "Epoch 50/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 22.0782 - mae: 3.0830 - val_loss: 4.5207 - val_mae: 1.3481\n",
      "Epoch 51/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 25.4962 - mae: 3.1887 - val_loss: 6.4355 - val_mae: 1.6294\n",
      "Epoch 52/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 22.5768 - mae: 3.0425 - val_loss: 4.6395 - val_mae: 1.3609\n",
      "Epoch 53/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 21.7025 - mae: 2.9118 - val_loss: 4.2075 - val_mae: 1.3258\n",
      "Epoch 54/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 26.3818 - mae: 3.2213 - val_loss: 4.3271 - val_mae: 1.4879\n",
      "Epoch 55/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 21.0421 - mae: 3.0307 - val_loss: 3.8503 - val_mae: 1.2562\n",
      "Epoch 56/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 20.5159 - mae: 2.9927 - val_loss: 5.7233 - val_mae: 1.5140\n",
      "Epoch 57/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 24.9212 - mae: 3.1560 - val_loss: 11.9062 - val_mae: 2.1884\n",
      "Epoch 58/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 21.9352 - mae: 3.0676 - val_loss: 4.1764 - val_mae: 1.3369\n",
      "Epoch 59/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 20.5460 - mae: 2.9347 - val_loss: 4.2472 - val_mae: 1.3918\n",
      "Epoch 60/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 23.7698 - mae: 3.0954 - val_loss: 14.9694 - val_mae: 2.5565\n",
      "Epoch 61/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 23.7555 - mae: 3.1001 - val_loss: 8.3653 - val_mae: 1.8375\n",
      "Epoch 62/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 20.9039 - mae: 2.9944 - val_loss: 8.4055 - val_mae: 1.9646\n",
      "Epoch 63/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 23.5116 - mae: 3.1393 - val_loss: 3.9907 - val_mae: 1.2763\n",
      "Epoch 64/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 20.9282 - mae: 2.8791 - val_loss: 4.0176 - val_mae: 1.2424\n",
      "Epoch 65/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 23.8486 - mae: 3.0570 - val_loss: 3.9455 - val_mae: 1.2738\n",
      "Epoch 66/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 22.5335 - mae: 3.0168 - val_loss: 4.3150 - val_mae: 1.3818\n",
      "Epoch 67/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 19.3819 - mae: 2.8252 - val_loss: 10.3476 - val_mae: 2.0974\n",
      "Epoch 68/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 21.7582 - mae: 3.0245 - val_loss: 5.0649 - val_mae: 1.3893\n",
      "Epoch 69/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 18.9968 - mae: 2.6976 - val_loss: 3.7278 - val_mae: 1.2031\n",
      "Epoch 70/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 17.6849 - mae: 2.6523 - val_loss: 4.3587 - val_mae: 1.3096\n",
      "Epoch 71/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 19.3816 - mae: 2.7570 - val_loss: 5.6352 - val_mae: 1.4972\n",
      "Epoch 72/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 21.2407 - mae: 2.8206 - val_loss: 5.7337 - val_mae: 1.6357\n",
      "Epoch 73/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 30.0857 - mae: 3.3965 - val_loss: 8.5293 - val_mae: 1.9059\n",
      "Epoch 74/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 20.8568 - mae: 2.8967 - val_loss: 3.8158 - val_mae: 1.2100\n",
      "Epoch 75/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 19.1984 - mae: 2.7452 - val_loss: 3.8628 - val_mae: 1.2324\n",
      "Epoch 76/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 22.5682 - mae: 2.9333 - val_loss: 13.2207 - val_mae: 2.5160\n",
      "Epoch 77/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 30.0021 - mae: 3.3563 - val_loss: 4.6877 - val_mae: 1.3701\n",
      "Epoch 78/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 17.3652 - mae: 2.7374 - val_loss: 4.1054 - val_mae: 1.3571\n",
      "Epoch 79/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 20.3626 - mae: 2.9405 - val_loss: 6.7238 - val_mae: 1.6592\n",
      "Epoch 80/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 21.0230 - mae: 2.9828 - val_loss: 8.4583 - val_mae: 1.8181\n",
      "Epoch 81/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 19.1892 - mae: 2.6921 - val_loss: 5.0142 - val_mae: 1.5722\n",
      "Epoch 82/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 19.9271 - mae: 2.8318 - val_loss: 3.9042 - val_mae: 1.2887\n",
      "Epoch 83/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 990us/step - loss: 18.8713 - mae: 2.6807 - val_loss: 4.3155 - val_mae: 1.2919\n",
      "Epoch 84/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 21.9894 - mae: 2.9306 - val_loss: 6.1789 - val_mae: 1.6011\n",
      "Epoch 85/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 16.9581 - mae: 2.4851 - val_loss: 10.5884 - val_mae: 2.1561\n",
      "Epoch 86/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 23.4618 - mae: 2.9711 - val_loss: 4.4640 - val_mae: 1.3133\n",
      "Epoch 87/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 20.7301 - mae: 2.8398 - val_loss: 5.3711 - val_mae: 1.5356\n",
      "Epoch 88/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 19.7798 - mae: 2.7660 - val_loss: 4.2361 - val_mae: 1.3303\n",
      "Epoch 89/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 20.7302 - mae: 2.8721 - val_loss: 4.8001 - val_mae: 1.4128\n",
      "Epoch 90/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 17.9242 - mae: 2.6120 - val_loss: 4.0991 - val_mae: 1.3000\n",
      "Epoch 91/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 22.8569 - mae: 3.0000 - val_loss: 4.6306 - val_mae: 1.4584\n",
      "Epoch 92/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 22.6480 - mae: 2.9762 - val_loss: 4.8727 - val_mae: 1.4017\n",
      "Epoch 93/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 21.7954 - mae: 2.8604 - val_loss: 8.6049 - val_mae: 1.8150\n",
      "Epoch 94/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 19.2702 - mae: 2.7556 - val_loss: 8.4969 - val_mae: 1.8907\n",
      "Epoch 95/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 23.6001 - mae: 2.9747 - val_loss: 3.7814 - val_mae: 1.2167\n",
      "Epoch 96/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 20.5129 - mae: 2.6444 - val_loss: 3.8476 - val_mae: 1.2399\n",
      "Epoch 97/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 19.2262 - mae: 2.7803 - val_loss: 4.4303 - val_mae: 1.3777\n",
      "Epoch 98/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 19.4572 - mae: 2.7028 - val_loss: 4.4713 - val_mae: 1.3467\n",
      "Epoch 99/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 18.9726 - mae: 2.7655 - val_loss: 5.2766 - val_mae: 1.3981\n",
      "Epoch 100/100\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 21.4003 - mae: 2.9188 - val_loss: 4.0006 - val_mae: 1.2287\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "# Define the MLP model\n",
    "mlp = Sequential() # fill in parameters\n",
    "mlp.add(Dense(128, activation='relu', input_dim=X_train.shape[1]))  # Input layer, 128 neurons, ReLU activation\n",
    "mlp.add(Dropout(0.2))  # Dropout layer to prevent overfitting\n",
    "mlp.add(Dense(64, activation='relu'))  # Hidden layer with 64 neurons, ReLU activation\n",
    "mlp.add(Dense(32, activation='relu'))  # Another hidden layer with 32 neurons\n",
    "mlp.add(Dense(1))  # Output layer with 1 neuron for regression (predicting a continuous value)\n",
    "\n",
    "# Compile the model\n",
    "# you can modify the code if necessary\n",
    "mlp.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n",
    "\n",
    "# Train the model\n",
    "history = mlp.fit(\n",
    "    X_train, y_train,  # Training data\n",
    "    epochs=100,  # Number of epochs for training\n",
    "    batch_size=32,  # Batch size\n",
    "    validation_data=(X_val, y_val),  # Validation data\n",
    "    verbose=1 \n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "zD7thWRIQ0tK",
   "metadata": {
    "id": "zD7thWRIQ0tK"
   },
   "source": [
    "### Evaluation and Discussion\n",
    "\n",
    "\n",
    "*   Analyze why this model performed well or poorly for this specific problem and dataset.\n",
    "*   Discuss the strengths and weaknesses of this approach, with particular attention to potential overfitting, underfitting, or any other relevant observations.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "QHi5u7s8I9qW",
   "metadata": {
    "id": "QHi5u7s8I9qW"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 914us/step - loss: 3.5159 - mae: 1.1834\n",
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step \n",
      "Test Loss (MSE): 3.459104537963867\n",
      "Test MAE: 1.1653990745544434\n",
      "Final Training Loss (MSE): 20.865951538085938\n",
      "Final Validation Loss (MSE): 4.000646114349365\n",
      "Final Training MAE: 2.8869597911834717\n",
      "Final Validation MAE: 1.228691816329956\n",
      "First few residuals (actual - predicted):\n",
      "[-0.16228104 -0.72394562 -0.01425171 -0.10179901  2.00271606  0.00528717\n",
      " -0.47060013  0.10610008 -2.99743652  0.35032463]\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on test data\n",
    "loss, mae = mlp.evaluate(X_test_scaled, y_test, verbose=1)\n",
    "\n",
    "train_loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "train_mae = history.history['mae']\n",
    "val_mae = history.history['val_mae']\n",
    "\n",
    "y_pred = mlp.predict(X_test_scaled)\n",
    "residuals = y_test.values - y_pred.flatten()\n",
    "\n",
    "# Print the evaluation results\n",
    "print(f\"Test Loss (MSE): {loss}\")\n",
    "print(f\"Test MAE: {mae}\")\n",
    "\n",
    "print(f\"Final Training Loss (MSE): {train_loss[-1]}\")\n",
    "print(f\"Final Validation Loss (MSE): {val_loss[-1]}\")\n",
    "print(f\"Final Training MAE: {train_mae[-1]}\")\n",
    "print(f\"Final Validation MAE: {val_mae[-1]}\")\n",
    "\n",
    "print(\"First few residuals (actual - predicted):\")\n",
    "print(residuals[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfee286c-6200-47d0-9ef3-e2114e4e79b3",
   "metadata": {},
   "source": [
    "# Discussion:\n",
    "\n",
    "### Model well or poorly:\n",
    "High Training Loss: relatively good performance on the validation set, the training loss is high, indicating the model is not learning effectively on the training data.\n",
    "\n",
    "### Test Loss and MAE:\n",
    "The Test Loss (MSE) of 3.31 and Test MAE of 1.21 indicate that the model's performance is reasonable but not perfect. \n",
    "\n",
    "### Training vs Validation Loss and MAE:\n",
    "The Training Loss (MSE) of 20.95 and Training MAE of 2.77 are considerably higher than the validation and test losses. This suggests that the model is struggling to generalize well to unseen data, which can be a sign of overfitting.\n",
    "\n",
    "### Residuals:\n",
    "The large residual of -4.20 on the 9th data point indicates that the model made a particularly large error on this instance.\n",
    "\n",
    "### Potential Overfitting:\n",
    "The model's significantly better performance on the validation set compared to the training set, with a much lower validation loss (3.78 vs 20.95 for MSE), suggests potential overfitting. The model might have memorized the training data too well and failed to generalize to the broader dataset.\n",
    "\n",
    "### Potential Underfitting:\n",
    "The model could be underfitting on the training data due to not being complex enough. The relatively high training loss and MAE, despite having a deep architecture, suggest that the model might not be capturing the underlying patterns in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61643218",
   "metadata": {
    "id": "61643218"
   },
   "source": [
    "# 2. RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e2228a",
   "metadata": {
    "id": "e9e2228a"
   },
   "source": [
    "##  2.1 Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c89af332",
   "metadata": {
    "id": "c89af332"
   },
   "source": [
    "\n",
    "**Problem Statement:**\n",
    "\n",
    "The problem at hand is to develop a model capable of forecasting the future stock prices of a given company with precision. Similarly, we aim to predict the future stock prices of Apple Inc. (AAPL) based on historical price data.\n",
    "\n",
    "Compared to Multilayer Perceptron (MLP), Recurrent Neural Networks (RNNs) are better suited for time series data like stock price prediction due to their ability to handle sequential data, capture temporal dependencies, and automatically extract relevant features, enabling more accurate forecasting and adaptation to dynamic market conditions.\n",
    "\n",
    "\n",
    "**Data Description:**\n",
    "\n",
    "The dataset used in this project is similar to Question 1\n",
    "1. **Timeframe**: 2014.1.1-2024.1.1\n",
    "2. **Geography**: The dataset primarily focuses on AAPL stock trading in the United States market.\n",
    "3. **Source**: yahoo finance\n",
    "4. **Target variable:**closing price of AAPL stock price.\n",
    "5. **Features:** The independent (features) variables consist of various market indicators and historical price data, including opening price, closing price, highest price, lowest price, trading volume."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41c49b3d",
   "metadata": {
    "id": "41c49b3d"
   },
   "source": [
    "## 2.2 Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9waxhRYTjZJ",
   "metadata": {
    "id": "a9waxhRYTjZJ"
   },
   "source": [
    "### Task 1:  Model Implementation\n",
    "Using the same dataset,\n",
    "\n",
    "*   Define the RNN model architecture using the Sequential class from keras.models. Add an RNN layer with a specified number of units, followed by a Dense output layer.\n",
    "*   Compile the model using the compile() method, specifying the Adam optimizer with a learning rate and mean squared error loss function.\n",
    "*   Train the RNN model using the training data.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fA_zPt0tVAFg",
   "metadata": {
    "id": "fA_zPt0tVAFg",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Applications/anaconda3/lib/python3.12/site-packages/keras/src/layers/rnn/rnn.py:200: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(**kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 9207.9062 - mae: 77.7148 - val_loss: 8625.6582 - val_mae: 75.5627\n",
      "Epoch 2/50\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 9226.1240 - mae: 79.0824 - val_loss: 8329.0879 - val_mae: 75.2163\n",
      "Epoch 3/50\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8745.5332 - mae: 78.3662 - val_loss: 8033.2129 - val_mae: 74.7273\n",
      "Epoch 4/50\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 8536.4619 - mae: 77.7184 - val_loss: 7727.9810 - val_mae: 74.0059\n",
      "Epoch 5/50\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7952.8359 - mae: 75.4097 - val_loss: 7415.4648 - val_mae: 72.9393\n",
      "Epoch 6/50\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7622.3789 - mae: 74.3323 - val_loss: 7092.7612 - val_mae: 71.3878\n",
      "Epoch 7/50\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 7347.0630 - mae: 72.9685 - val_loss: 6748.8301 - val_mae: 69.3609\n",
      "Epoch 8/50\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6940.2607 - mae: 70.6559 - val_loss: 6389.5322 - val_mae: 67.0049\n",
      "Epoch 9/50\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6438.1587 - mae: 67.4528 - val_loss: 6028.6758 - val_mae: 64.2581\n",
      "Epoch 10/50\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 6138.9224 - mae: 65.3387 - val_loss: 5664.4800 - val_mae: 61.5186\n",
      "Epoch 11/50\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5943.8843 - mae: 63.0898 - val_loss: 5308.3828 - val_mae: 58.5032\n",
      "Epoch 12/50\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5267.1357 - mae: 58.2483 - val_loss: 4967.7461 - val_mae: 55.5542\n",
      "Epoch 13/50\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 5298.7842 - mae: 57.9208 - val_loss: 4641.2188 - val_mae: 52.6541\n",
      "Epoch 14/50\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4883.1567 - mae: 54.6367 - val_loss: 4339.4502 - val_mae: 49.7997\n",
      "Epoch 15/50\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4427.0024 - mae: 50.7651 - val_loss: 4062.2708 - val_mae: 47.1183\n",
      "Epoch 16/50\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4510.1147 - mae: 50.4961 - val_loss: 3799.1111 - val_mae: 44.6380\n",
      "Epoch 17/50\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 4095.2480 - mae: 46.8248 - val_loss: 3564.1619 - val_mae: 42.3024\n",
      "Epoch 18/50\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 972us/step - loss: 3618.1216 - mae: 43.1549 - val_loss: 3350.0491 - val_mae: 40.1252\n",
      "Epoch 19/50\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 995us/step - loss: 3497.9651 - mae: 41.8768 - val_loss: 3151.9365 - val_mae: 38.1518\n",
      "Epoch 20/50\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3160.5703 - mae: 38.3337 - val_loss: 2967.7905 - val_mae: 36.3650\n",
      "Epoch 21/50\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 3150.8147 - mae: 38.3810 - val_loss: 2798.6865 - val_mae: 34.5313\n",
      "Epoch 22/50\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2963.8293 - mae: 36.6179 - val_loss: 2644.9734 - val_mae: 32.9046\n",
      "Epoch 23/50\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2747.1277 - mae: 34.4034 - val_loss: 2498.9475 - val_mae: 31.4896\n",
      "Epoch 24/50\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2644.2766 - mae: 33.5394 - val_loss: 2366.2795 - val_mae: 30.0843\n",
      "Epoch 25/50\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2532.3840 - mae: 32.4928 - val_loss: 2242.3132 - val_mae: 28.8367\n",
      "Epoch 26/50\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2296.4375 - mae: 29.9023 - val_loss: 2128.4121 - val_mae: 27.7119\n",
      "Epoch 27/50\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2221.6189 - mae: 29.3204 - val_loss: 2018.3490 - val_mae: 26.5612\n",
      "Epoch 28/50\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 2209.2590 - mae: 29.1944 - val_loss: 1914.8148 - val_mae: 25.5365\n",
      "Epoch 29/50\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1943.3059 - mae: 26.1153 - val_loss: 1820.2609 - val_mae: 24.7485\n",
      "Epoch 30/50\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1915.7325 - mae: 26.9728 - val_loss: 1729.5724 - val_mae: 23.9471\n",
      "Epoch 31/50\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1813.9132 - mae: 25.3087 - val_loss: 1644.1748 - val_mae: 23.4220\n",
      "Epoch 32/50\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1716.1199 - mae: 25.0313 - val_loss: 1565.3767 - val_mae: 23.0041\n",
      "Epoch 33/50\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1604.3618 - mae: 24.3005 - val_loss: 1492.8234 - val_mae: 22.6317\n",
      "Epoch 34/50\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1451.3344 - mae: 22.5570 - val_loss: 1423.2522 - val_mae: 22.2969\n",
      "Epoch 35/50\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1430.6232 - mae: 23.2114 - val_loss: 1357.6411 - val_mae: 22.0078\n",
      "Epoch 36/50\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1317.2985 - mae: 22.3920 - val_loss: 1296.6964 - val_mae: 21.7032\n",
      "Epoch 37/50\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1374.4991 - mae: 23.4583 - val_loss: 1237.7732 - val_mae: 21.4470\n",
      "Epoch 38/50\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1239.7834 - mae: 22.2440 - val_loss: 1183.9113 - val_mae: 21.2027\n",
      "Epoch 39/50\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1232.1062 - mae: 22.6282 - val_loss: 1131.8478 - val_mae: 21.0050\n",
      "Epoch 40/50\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1143.0444 - mae: 21.7639 - val_loss: 1083.1965 - val_mae: 20.7503\n",
      "Epoch 41/50\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1107.6146 - mae: 21.7821 - val_loss: 1036.9343 - val_mae: 20.5155\n",
      "Epoch 42/50\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 964.9060 - mae: 19.9466 - val_loss: 993.3796 - val_mae: 20.2068\n",
      "Epoch 43/50\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 1039.6628 - mae: 21.1736 - val_loss: 952.8321 - val_mae: 20.0489\n",
      "Epoch 44/50\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 954.0935 - mae: 20.6994 - val_loss: 913.4552 - val_mae: 19.6601\n",
      "Epoch 45/50\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 965.0520 - mae: 20.6737 - val_loss: 877.4202 - val_mae: 19.4443\n",
      "Epoch 46/50\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 824.6928 - mae: 19.6942 - val_loss: 842.1569 - val_mae: 19.1010\n",
      "Epoch 47/50\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 816.6030 - mae: 19.3524 - val_loss: 808.8550 - val_mae: 18.8589\n",
      "Epoch 48/50\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 790.9602 - mae: 18.9354 - val_loss: 777.4804 - val_mae: 18.5540\n",
      "Epoch 49/50\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1ms/step - loss: 801.1502 - mae: 19.4725 - val_loss: 746.9963 - val_mae: 18.2274\n",
      "Epoch 50/50\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 744.6073 - mae: 19.0403 - val_loss: 718.1558 - val_mae: 17.9393\n"
     ]
    }
   ],
   "source": [
    "X_val_scaled = X_val.reshape((X_val.shape[0], 1, X_val.shape[1]))\n",
    "X_train_scaled = X_train.reshape((X_train.shape[0], 1, X_train.shape[1]))\n",
    "X_test_scaled = X_test_scaled.reshape((X_test_scaled.shape[0], 1, X_test_scaled.shape[1]))\n",
    "# Define the RNN model\n",
    "rnn = Sequential()\n",
    "\n",
    "# Add RNN layer (units can be adjusted based on experimentation)\n",
    "rnn.add(SimpleRNN(units=50, return_sequences=False, input_shape=(X_train_scaled.shape[1], X_train_scaled.shape[2])))\n",
    "\n",
    "# Add output layer\n",
    "rnn.add(Dense(1))  # Predicting a single value (AAPL closing price)\n",
    "\n",
    "# Compile the model\n",
    "rnn.compile(optimizer=Adam(learning_rate=0.001), loss='mse', metrics=['mae'])\n",
    "\n",
    "# Train the model\n",
    "history = rnn.fit(\n",
    "    X_train_scaled,  # Training features (scaled)\n",
    "    y_train,         # Training target variable (closing price)\n",
    "    epochs=50,       # Train for 50 epochs\n",
    "    batch_size=32,   # Use a batch size of 32\n",
    "    validation_data=(X_val_scaled, y_val),  # Validation data\n",
    "    verbose=1        # Display training progress\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "trTo92DqVHmK",
   "metadata": {
    "id": "trTo92DqVHmK"
   },
   "source": [
    "### Task 2: Evaluation and Discussion\n",
    "\n",
    "\n",
    "*   Compared with the MLP model, analyze why this model performed better or worse for this specific problem and dataset.\n",
    "*   Discuss the strengths and weaknesses of this approach, with particular attention to potential overfitting, underfitting, or any other relevant observations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "isjlrvPSVHEb",
   "metadata": {
    "id": "isjlrvPSVHEb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 955us/step - loss: 778.6627 - mae: 19.1387\n",
      "Test Loss (MSE): 754.56005859375\n",
      "Test MAE: 18.769922256469727\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model on test data\n",
    "loss, mae = rnn.evaluate(X_test_scaled, y_test, verbose=1)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(f\"Test Loss (MSE): {loss}\")\n",
    "print(f\"Test MAE: {mae}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8421813-2fd8-40b2-b5be-030cab80860d",
   "metadata": {},
   "source": [
    "# Discussion\n",
    "\n",
    "### Strengths:\n",
    "Sequential Data Handling: RNNs are designed for sequential data like stock prices, making them well-suited to capture temporal dependencies and patterns that MLPs might miss. They can learn relationships between past and future time steps, which is crucial for time series forecasting.\n",
    "\n",
    "Dynamic Adaptation: RNNs can adapt to changing market conditions by \"remembering\" previous data points, potentially offering better predictions when the temporal structure is significant.\n",
    "\n",
    "### Weaknesses:\n",
    "Overfitting: RNNs, especially with small datasets or noisy data like stock prices, are prone to overfitting. If the model becomes too complex or trained too long, it can learn noise rather than meaningful patterns. \n",
    "\n",
    "Underfitting: If the model is too simple (e.g., too few units or epochs), it might not capture the full complexity of the stock price data, leading to underfitting. \n",
    "\n",
    "Vanishing Gradients: RNNs can suffer from the vanishing gradient problem, especially with long time sequences. This makes it harder for the network to learn long-term dependencies, limiting its effectiveness for tasks requiring long-range memory."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "Vkwrulvo63V6",
   "metadata": {
    "id": "Vkwrulvo63V6"
   },
   "source": [
    "## 3. Deep Learning for Classification - Back-propagation from Scratch"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0rrG5J86jee",
   "metadata": {
    "id": "c0rrG5J86jee"
   },
   "source": [
    "\n",
    "**Problem Statement:**\n",
    "\n",
    "The objective is to train a neural network **from scratch using NumPy** to gain a deeper understanding of backpropagation.\n",
    "\n",
    "\n",
    "*   You should implement the forward pass and backward pass from\n",
    "scratch, manually coding everything (e.g., cross-entropy loss, softmax, sigmoid activation) using NumPy.\n",
    "*   Provide explanations for each step's code and computations.\n",
    "*   Train the model for 3 epochs.\n",
    "\n",
    "**Data Description:**\n",
    "\n",
    "This project uses a standard **MNIST benchmark dataset** (provided in tensorflow.keras.datasets package), a well-known dataset in machine learning and computer vision. The MNIST dataset contains grayscale images of handwritten digits (0-9), commonly used for training and testing digit recognition models.\n",
    "\n",
    "**Model Guidance:**\n",
    "\n",
    "The network will include:\n",
    "* Sigmoid activations for neurons, softmax activation for the output layer, and cross-entropy loss.\n",
    "* An architecture with **two hidden layers, each containing 32 neurons**. The number of neurons at each layer will be as follows: **784 - 32 - 32 - 10**.\n",
    "* Weights initialized from a normal distribution with **mean 0** and **variance 1 / max(n_in, n_out)**, where n_in and n_out represent the number of input and output neurons, respectively. **Biases will be initialized to 0**.\n",
    "\n",
    "**Evaluation and Discussion:**\n",
    "\n",
    "After completing the implementation from scratch, you need to repeat the same classification task using a deep learning library such as **PyTorch or TensorFlow**. This will involve using built-in layers and backpropagation. Compare and discuss the results obtained from these two approaches.\n",
    "\n",
    "**Note**: You should use a constant seed for random number generation to ensure the reproducibility of their results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "479ab19d",
   "metadata": {
    "id": "479ab19d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, Loss: 2.434248573305333\n",
      "Test Accuracy: 9.80%\n"
     ]
    }
   ],
   "source": [
    "# write your code here.\n",
    "\n",
    "# Fixing the random seed for reproducibility\n",
    "np.random.seed(42)\n",
    "tf.random.set_seed(42)\n",
    "\n",
    "# Load the MNIST dataset\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n",
    "\n",
    "# Reshape the data to 784-dimensional vectors and normalize it\n",
    "x_train = x_train.reshape(-1, 784) / 255.0\n",
    "x_test = x_test.reshape(-1, 784) / 255.0\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "y_train_onehot = np.eye(10)[y_train]\n",
    "y_test_onehot = np.eye(10)[y_test]\n",
    "\n",
    "# Sigmoid activation function\n",
    "def sigmoid(x):\n",
    "    return 1 / (1 + np.exp(-x))\n",
    "\n",
    "# Sigmoid derivative\n",
    "def sigmoid_derivative(x):\n",
    "    return x * (1 - x)\n",
    "\n",
    "# Softmax activation function\n",
    "def softmax(x):\n",
    "    exp_x = np.exp(x - np.max(x, axis=1, keepdims=True))  # Stability improvement\n",
    "    return exp_x / np.sum(exp_x, axis=1, keepdims=True)\n",
    "\n",
    "# Cross-entropy loss function\n",
    "def cross_entropy_loss(y_pred, y_true):\n",
    "    m = y_true.shape[0]\n",
    "    return -np.sum(y_true * np.log(y_pred + 1e-10)) / m\n",
    "\n",
    "# Initialize weights and biases\n",
    "def initialize_parameters(input_size, hidden_size, output_size):\n",
    "    # Randomly initialize weights with a normal distribution\n",
    "    W1 = np.random.randn(input_size, hidden_size) * np.sqrt(1. / input_size)\n",
    "    b1 = np.zeros((1, hidden_size))\n",
    "    W2 = np.random.randn(hidden_size, hidden_size) * np.sqrt(1. / hidden_size)\n",
    "    b2 = np.zeros((1, hidden_size))\n",
    "    W3 = np.random.randn(hidden_size, output_size) * np.sqrt(1. / hidden_size)\n",
    "    b3 = np.zeros((1, output_size))\n",
    "    \n",
    "    return W1, b1, W2, b2, W3, b3\n",
    "\n",
    "# Forward pass function\n",
    "def forward_pass(x, W1, b1, W2, b2, W3, b3):\n",
    "    z1 = np.dot(x, W1) + b1\n",
    "    a1 = sigmoid(z1)\n",
    "    \n",
    "    z2 = np.dot(a1, W2) + b2\n",
    "    a2 = sigmoid(z2)\n",
    "    \n",
    "    z3 = np.dot(a2, W3) + b3\n",
    "    a3 = softmax(z3)\n",
    "    \n",
    "    return a1, a2, a3\n",
    "\n",
    "# Backward pass function (Backpropagation)\n",
    "def backward_pass(x, y_true, a1, a2, a3, W1, W2, W3):\n",
    "    m = x.shape[0]\n",
    "    \n",
    "    # Output layer error (cross-entropy + softmax)\n",
    "    dz3 = a3 - y_true\n",
    "    dW3 = np.dot(a2.T, dz3) / m\n",
    "    db3 = np.sum(dz3, axis=0, keepdims=True) / m\n",
    "    \n",
    "    # Hidden layer 2 error\n",
    "    dz2 = np.dot(dz3, W3.T) * sigmoid_derivative(a2)\n",
    "    dW2 = np.dot(a1.T, dz2) / m\n",
    "    db2 = np.sum(dz2, axis=0, keepdims=True) / m\n",
    "    \n",
    "    # Hidden layer 1 error\n",
    "    dz1 = np.dot(dz2, W2.T) * sigmoid_derivative(a1)\n",
    "    dW1 = np.dot(x.T, dz1) / m\n",
    "    db1 = np.sum(dz1, axis=0, keepdims=True) / m\n",
    "    \n",
    "    return dW1, db1, dW2, db2, dW3, db3\n",
    "\n",
    "# Training function\n",
    "def train(x_train, y_train, epochs=3, learning_rate=0.01):\n",
    "    input_size = x_train.shape[1]\n",
    "    hidden_size = 32\n",
    "    output_size = 10\n",
    "    \n",
    "    # Initialize parameters\n",
    "    W1, b1, W2, b2, W3, b3 = initialize_parameters(input_size, hidden_size, output_size)\n",
    "    \n",
    "    # Train the network\n",
    "    for epoch in range(epochs):\n",
    "        # Forward pass\n",
    "        a1, a2, a3 = forward_pass(x_train, W1, b1, W2, b2, W3, b3)\n",
    "        \n",
    "        # Compute the loss\n",
    "        loss = cross_entropy_loss(a3, y_train)\n",
    "        \n",
    "        # Backward pass\n",
    "        dW1, db1, dW2, db2, dW3, db3 = backward_pass(x_train, y_train, a1, a2, a3, W1, W2, W3)\n",
    "        \n",
    "        # Update weights and biases using gradient descent\n",
    "        W1 -= learning_rate * dW1\n",
    "        b1 -= learning_rate * db1\n",
    "        W2 -= learning_rate * dW2\n",
    "        b2 -= learning_rate * db2\n",
    "        W3 -= learning_rate * dW3\n",
    "        b3 -= learning_rate * db3\n",
    "        \n",
    "        # Print the loss every 100 iterations\n",
    "        if epoch % 100 == 0:\n",
    "            print(f\"Epoch {epoch}, Loss: {loss}\")\n",
    "    \n",
    "    return W1, b1, W2, b2, W3, b3\n",
    "\n",
    "# Prediction function\n",
    "def predict(x, W1, b1, W2, b2, W3, b3):\n",
    "    _, _, a3 = forward_pass(x, W1, b1, W2, b2, W3, b3)\n",
    "    return np.argmax(a3, axis=1)\n",
    "\n",
    "# Evaluate the model\n",
    "def evaluate(x, y_true, W1, b1, W2, b2, W3, b3):\n",
    "    y_pred = predict(x, W1, b1, W2, b2, W3, b3)\n",
    "    accuracy = np.mean(y_pred == np.argmax(y_true, axis=1))\n",
    "    return accuracy\n",
    "\n",
    "# Train the model\n",
    "W1, b1, W2, b2, W3, b3 = train(x_train, y_train_onehot, epochs=3, learning_rate=0.01)\n",
    "\n",
    "# Evaluate the model on the test set\n",
    "accuracy = evaluate(x_test, y_test_onehot, W1, b1, W2, b2, W3, b3)\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0340d088-bf65-4fc6-b813-51afb0516e23",
   "metadata": {},
   "source": [
    "# Discussion:\n",
    "1. Advantages of Training from Scratch: This approach gives a deeper understanding of how backpropagation works by manually implementing the forward and backward passes. It also helps understand how the gradients are propagated and how the weights are updated.\n",
    "2. Limitations: This implementation is less efficient than using frameworks like TensorFlow or PyTorch, which optimize these operations. Additionally, this model may not converge as efficiently as models trained using these libraries due to the lack of advanced optimization techniques such as momentum or adaptive learning rates."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
